{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Sense of Unstructured Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering (Un-supervised Learning) - assign data point to one group / family, grouping data according to similarity\n",
    "\n",
    "    find topics that people share\n",
    "    find dimensions that lead to failure\n",
    "    use when you dont know label\n",
    "\n",
    "Classification (Supervised Learning) - give labels to group data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means (fast, fast, fast) - need quantatative data (numbers)\n",
    "Assumptions: we can express any data point as a list (vecrtor) of conitnuous values\n",
    "k = number of clusters\n",
    "\n",
    "Dis-simalrity - sum (x_d - y_d)^2\n",
    "\n",
    "K-means Algorithm (Lloyd's algorithm) - minimize global dis-simialrity\n",
    "K-means++ Algorithm - better initialization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHEN TO USE K-MEANS\n",
    "\n",
    "is your data featurized? - needs vector of data\n",
    "is each feature quantatative? - needs to be a quantity\n",
    "is the data normalized? - cluster will be scewed\n",
    "too many features? - find useful and useless features \n",
    "\n",
    "FEATURE RREDUCTION - PRINCIPAL COMPONENT ANALYSIS ALGORITHM (helps find most important feature)\n",
    "run PCA before running K-mean (pre-processing data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ways to find optimal K\n",
    "plot global dismalrity v.s K groups (find elbow)\n",
    "\n",
    "Look Up:\n",
    "AIC and BIC (Penality Item for K-clustering)\n",
    "\n",
    "Hard clustering - put all data points into ONE distinctive cluster\n",
    "\n",
    "Soft clustering - each data group has a range or probability that it belongs to a certain group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROBLEMS WITH K-MEANS\n",
    "k-means defines distance as the euclidean distance\n",
    "radial cases where the data is not grouped by sphere but one group is in another\n",
    "edge cases where groups are close to eachother (larger groups have disadvantage)\n",
    "k-means is very sensitive to outliers (if one group is very far away it will consider that as a single group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STREAMING DATA - data that keeps coming in (new users for an app)\n",
    "Nonparametric Bayesian Networks (Mad Bayes)\n",
    "You may not want fixed k-clusters for streaming data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 DIFFERENT APPROCAHCES FOR FEATURE REDUCTION\n",
    "1. PRINCIPLE COMPONENENT ANALYSIS - linear projection that spreads data as much as possible\n",
    "    1. PCA is very fast\n",
    "2. T-DISTRIBUTED STOCHASTIC NEIGHBOR EMBEDDING - non-linear embedding that tries to keep close-by points close\n",
    "    1. t-SNE - is better at finding clusters\n",
    "    2. Uses Kullback-Leibler divergence to measure the \"distance\" between distributions and minimizes this object function.\n",
    "\n",
    "WHOLE POINT OF THIS DIMENSIONALITY REDUCTION IS SO THAT US HUMANS CAN SEE VISUALLY WHERE OUR CLUSTERS LIE.\n",
    "\n",
    "Use covariance will find the variable with largest spread\n",
    "use correlation matrix if have different units"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
